{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9f9ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a8b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((64,64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5),(0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c5f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('./dataset',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb0a763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 * len(dataset)\n",
    "test_set = torch.utils.data.Subset(dataset,range(int(test_size)))\n",
    "train_set = torch.utils.data.Subset(dataset,range(int(test_size),len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ab6a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de1b7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'rock', 'scissors']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "279e9c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2c06015",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = train_set[581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea5d83fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6941, -0.6863, -0.6784,  ..., -0.5216, -0.5216, -0.5137],\n",
       "         [-0.6941, -0.6863, -0.6863,  ..., -0.6000, -0.6078, -0.6078],\n",
       "         [-0.6941, -0.6941, -0.6941,  ..., -0.6078, -0.6078, -0.6000],\n",
       "         ...,\n",
       "         [-0.7412, -0.7412, -0.7490,  ..., -0.6784, -0.6706, -0.6627],\n",
       "         [-0.7412, -0.7333, -0.7490,  ..., -0.6784, -0.6706, -0.6706],\n",
       "         [-0.7020, -0.7098, -0.7255,  ..., -0.6784, -0.6706, -0.6471]],\n",
       "\n",
       "        [[-0.0902, -0.0824, -0.0667,  ...,  0.0039, -0.0039, -0.0118],\n",
       "         [-0.0824, -0.0745, -0.0667,  ...,  0.0510,  0.0431,  0.0275],\n",
       "         [-0.0824, -0.0667, -0.0588,  ...,  0.0510,  0.0431,  0.0353],\n",
       "         ...,\n",
       "         [-0.0902, -0.0824, -0.0902,  ..., -0.0431, -0.0431, -0.0510],\n",
       "         [-0.0902, -0.0824, -0.0902,  ..., -0.0431, -0.0431, -0.0588],\n",
       "         [-0.0745, -0.0902, -0.1059,  ..., -0.0588, -0.0588, -0.0745]],\n",
       "\n",
       "        [[-0.8275, -0.8196, -0.8118,  ..., -0.6863, -0.6941, -0.6863],\n",
       "         [-0.8275, -0.8196, -0.8196,  ..., -0.7961, -0.7961, -0.7961],\n",
       "         [-0.8353, -0.8275, -0.8353,  ..., -0.8118, -0.8118, -0.8039],\n",
       "         ...,\n",
       "         [-0.8588, -0.8588, -0.8667,  ..., -0.8667, -0.8588, -0.8510],\n",
       "         [-0.8588, -0.8588, -0.8667,  ..., -0.8667, -0.8588, -0.8667],\n",
       "         [-0.8431, -0.8588, -0.8667,  ..., -0.8745, -0.8667, -0.8588]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2859af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df175d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73aedfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'rock', 'scissors']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138104b",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425827c1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
